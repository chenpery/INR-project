*** SLURM BATCH JOB 'galk-job' STARTING ***
*** Activating environment cs236781-project ***
2024-10-05 17:34:15,081 [INFO] device: cuda
2024-10-05 17:34:15,084 [INFO] Testing combination 1/150: {'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 16
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 17
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 18
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 19
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 20
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 21
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 22
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 23
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 24
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 25
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 27
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 28
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 30
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 31
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 34
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 35
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 37
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 38
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 40
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 41
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 42
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 43
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 44
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 47
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 50
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 52
Epoch    56: reducing learning rate of group 0 to 1.0000e-05.
2024-10-05 17:37:36,979 [INFO] curr best accuracy: 86.54, params: {'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}
2024-10-05 17:37:36,979 [INFO] New best accuracy: 86.54, params: {'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}
2024-10-05 17:37:36,980 [INFO] Testing combination 2/150: {'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 13
Epoch    17: reducing learning rate of group 0 to 1.0000e-04.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 18
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 19
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 22
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 24
Epoch    28: reducing learning rate of group 0 to 1.0000e-05.
2024-10-05 17:39:20,481 [INFO] curr best accuracy: 89.32, params: {'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}
2024-10-05 17:39:20,482 [INFO] New best accuracy: 89.32, params: {'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}
2024-10-05 17:39:20,482 [INFO] Testing combination 3/150: {'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 16
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 17
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 18
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 19
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 20
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 21
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 22
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 23
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 24
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 25
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 26
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 27
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 28
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 29
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 30
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 31
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 32
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 33
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 34
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 35
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 36
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 37
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 38
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 39
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 40
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 41
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 42
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 43
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 44
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 45
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 46
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 47
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 48
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 49
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 51
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 53
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 54
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 55
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 56
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 57
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 58
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 60
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 61
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 63
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 64
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 65
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 66
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 67
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 68
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 71
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 72
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 73
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 74
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 76
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 77
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 78
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 79
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 82
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 83
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 85
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 86
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 87
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 88
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 91
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 92
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 93
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 95
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 97
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 98
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 99
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 100
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 101
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 102
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 103
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 105
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 106
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 108
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 112
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 113
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 115
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 117
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 119
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 120
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 121
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 123
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 124
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 126
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 127
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 128
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 129
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 130
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 131
Epoch   135: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 137
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 138
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 142
Epoch   146: reducing learning rate of group 0 to 1.0000e-06.
Epoch   150: reducing learning rate of group 0 to 1.0000e-07.
2024-10-05 17:47:05,542 [INFO] curr best accuracy: 81.04, params: {'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}
2024-10-05 17:47:05,543 [INFO] Testing combination 4/150: {'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 18
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 19
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 23
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 24
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 27
Epoch    31: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 32
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 33
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 36
Epoch    40: reducing learning rate of group 0 to 1.0000e-06.
2024-10-05 17:48:51,088 [INFO] curr best accuracy: 89.48, params: {'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}
2024-10-05 17:48:51,088 [INFO] New best accuracy: 89.48, params: {'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}
2024-10-05 17:48:51,088 [INFO] Testing combination 5/150: {'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 17
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 18
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 19
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 20
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 24
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 25
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 27
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 28
Epoch    32: reducing learning rate of group 0 to 1.0000e-04.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 33
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 34
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 35
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 38
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 42
Epoch    46: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 50
Epoch    54: reducing learning rate of group 0 to 1.0000e-06.
Epoch    58: reducing learning rate of group 0 to 1.0000e-07.
2024-10-05 17:50:37,759 [INFO] curr best accuracy: 88.28, params: {'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}
2024-10-05 17:50:37,760 [INFO] Testing combination 6/150: {'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 16
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 17
Epoch    21: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 22
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 24
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 27
Epoch    31: reducing learning rate of group 0 to 1.0000e-06.
2024-10-05 17:51:47,737 [INFO] curr best accuracy: 87.98, params: {'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}
2024-10-05 17:51:47,738 [INFO] Testing combination 7/150: {'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 16
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 17
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 18
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 19
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 20
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 22
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 23
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 25
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 26
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 27
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 28
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 30
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 31
Epoch    35: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 36
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 37
Epoch    41: reducing learning rate of group 0 to 1.0000e-06.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 44
Epoch    48: reducing learning rate of group 0 to 1.0000e-07.
Epoch    52: reducing learning rate of group 0 to 1.0000e-08.
2024-10-05 17:53:15,456 [INFO] curr best accuracy: 86.8, params: {'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}
2024-10-05 17:53:15,457 [INFO] Testing combination 8/150: {'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 6
Epoch    10: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 14
Epoch    18: reducing learning rate of group 0 to 1.0000e-06.
Epoch    22: reducing learning rate of group 0 to 1.0000e-07.
2024-10-05 17:53:58,725 [INFO] curr best accuracy: 89.26, params: {'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}
2024-10-05 17:53:58,725 [INFO] Testing combination 9/150: {'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 16
Epoch    20: reducing learning rate of group 0 to 1.0000e-04.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 21
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 24
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 26
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 27
Epoch    31: reducing learning rate of group 0 to 1.0000e-05.
2024-10-05 17:57:29,036 [INFO] curr best accuracy: 89.56, params: {'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}
2024-10-05 17:57:29,036 [INFO] New best accuracy: 89.56, params: {'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}
2024-10-05 17:57:29,037 [INFO] Testing combination 10/150: {'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 17
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 18
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 19
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 20
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 22
Epoch    26: reducing learning rate of group 0 to 1.0000e-04.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 27
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 28
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 30
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 32
Epoch    36: reducing learning rate of group 0 to 1.0000e-05.
2024-10-05 18:00:55,769 [INFO] curr best accuracy: 88.24, params: {'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}
2024-10-05 18:00:55,769 [INFO] Testing combination 11/150: {'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 6
Epoch    10: reducing learning rate of group 0 to 1.0000e-04.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 17
Epoch    21: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 22
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 24
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 27
Epoch    31: reducing learning rate of group 0 to 1.0000e-06.
2024-10-05 18:02:17,873 [INFO] curr best accuracy: 89.56, params: {'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}
2024-10-05 18:02:17,874 [INFO] Testing combination 12/150: {'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 16
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 17
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 18
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 19
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 20
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 21
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 23
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 24
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 25
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 26
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 27
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 28
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 29
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 30
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 31
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 32
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 33
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 34
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 35
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 36
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 37
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 38
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 39
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 40
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 41
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 42
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 43
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 44
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 45
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 46
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 47
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 49
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 50
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 51
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 53
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 55
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 56
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 57
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 58
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 59
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 61
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 63
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 64
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 65
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 67
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 68
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 69
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 70
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 71
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 72
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 73
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 74
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 78
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 79
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 81
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 83
Epoch    87: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 88
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 92
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 94
Epoch    98: reducing learning rate of group 0 to 1.0000e-06.
2024-10-05 18:04:56,064 [INFO] curr best accuracy: 78.32, params: {'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}
2024-10-05 18:04:56,065 [INFO] Testing combination 13/150: {'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 10
Epoch    14: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 16
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 19
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 22
Epoch    26: reducing learning rate of group 0 to 1.0000e-06.
Epoch    30: reducing learning rate of group 0 to 1.0000e-07.
2024-10-05 18:06:14,115 [INFO] curr best accuracy: 87.6, params: {'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}
2024-10-05 18:06:14,116 [INFO] Testing combination 14/150: {'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 6
Epoch    10: reducing learning rate of group 0 to 1.0000e-04.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 14
Epoch    18: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 19
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 21
Epoch    25: reducing learning rate of group 0 to 1.0000e-06.
Epoch    29: reducing learning rate of group 0 to 1.0000e-07.
2024-10-05 18:07:09,670 [INFO] curr best accuracy: 88.54, params: {'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}
2024-10-05 18:07:09,671 [INFO] Testing combination 15/150: {'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 16
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 19
Epoch    23: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 24
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 25
Epoch    29: reducing learning rate of group 0 to 1.0000e-06.
2024-10-05 18:08:25,128 [INFO] curr best accuracy: 88.74, params: {'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}
2024-10-05 18:08:25,129 [INFO] Testing combination 16/150: {'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 16
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 17
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 21
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 24
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 27
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 28
Epoch    32: reducing learning rate of group 0 to 1.0000e-04.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 34
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 35
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 37
Epoch    41: reducing learning rate of group 0 to 1.0000e-05.
Epoch    45: reducing learning rate of group 0 to 1.0000e-06.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 46
Epoch    50: reducing learning rate of group 0 to 1.0000e-07.
Epoch    54: reducing learning rate of group 0 to 1.0000e-08.
2024-10-05 18:09:53,711 [INFO] curr best accuracy: 87.2, params: {'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}
2024-10-05 18:09:53,712 [INFO] Testing combination 17/150: {'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 1
Epoch     5: reducing learning rate of group 0 to 1.0000e-04.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 16
Epoch    20: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 21
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 23
Epoch    27: reducing learning rate of group 0 to 1.0000e-06.
2024-10-05 18:10:55,421 [INFO] curr best accuracy: 88.08, params: {'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}
2024-10-05 18:10:55,421 [INFO] Testing combination 18/150: {'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 16
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 17
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 18
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 19
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 20
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 21
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 22
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 23
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 25
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 26
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 27
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 29
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 30
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 31
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 32
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 33
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 34
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 35
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 37
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 38
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 39
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 40
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 41
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 42
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 43
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 44
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 46
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 48
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 49
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 52
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 53
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 54
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 55
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 58
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 60
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 62
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 66
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 67
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 68
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 69
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 71
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 73
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 76
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 77
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 78
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 80
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 82
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 83
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 84
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 85
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 87
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 88
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 89
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 90
Epoch    94: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 95
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 96
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 99
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 103
Epoch   107: reducing learning rate of group 0 to 1.0000e-06.
2024-10-05 18:16:12,500 [INFO] curr best accuracy: 83.6, params: {'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}
2024-10-05 18:16:12,501 [INFO] Testing combination 19/150: {'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 16
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 17
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 18
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 19
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 20
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 21
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 22
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 23
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 24
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 25
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 26
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 27
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 28
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 29
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 30
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 31
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 32
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 33
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 34
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 35
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 37
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 39
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 41
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 42
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 43
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 44
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 46
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 47
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 48
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 49
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 51
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 52
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 54
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 55
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 56
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 57
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 58
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 59
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 60
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 61
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 63
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 64
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 67
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 69
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 71
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 72
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 75
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 76
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 78
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 80
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 83
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 84
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 86
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 88
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 91
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 94
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 96
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 97
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 98
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 99
Epoch   103: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 104
Epoch   108: reducing learning rate of group 0 to 1.0000e-06.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 109
Epoch   113: reducing learning rate of group 0 to 1.0000e-07.
2024-10-05 18:25:52,872 [INFO] curr best accuracy: 85.58, params: {'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}
2024-10-05 18:25:52,873 [INFO] Testing combination 20/150: {'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 9
Epoch    13: reducing learning rate of group 0 to 1.0000e-04.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 16
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 18
Epoch    22: reducing learning rate of group 0 to 1.0000e-05.
2024-10-05 18:28:03,849 [INFO] curr best accuracy: 88.6, params: {'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}
2024-10-05 18:28:03,850 [INFO] Testing combination 21/150: {'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 10
Epoch    14: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 17
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 18
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 21
Epoch    25: reducing learning rate of group 0 to 1.0000e-06.
Epoch    29: reducing learning rate of group 0 to 1.0000e-07.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 31
Epoch    35: reducing learning rate of group 0 to 1.0000e-08.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 41
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 42
2024-10-05 18:29:37,948 [INFO] curr best accuracy: 89.02, params: {'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}
2024-10-05 18:29:37,948 [INFO] Testing combination 22/150: {'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 17
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 18
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 21
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 22
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 23
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 25
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 26
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 27
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 28
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 31
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 33
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 37
Epoch    41: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 42
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 43
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 44
Epoch    48: reducing learning rate of group 0 to 1.0000e-06.
2024-10-05 18:31:24,325 [INFO] curr best accuracy: 88.1, params: {'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}
2024-10-05 18:31:24,326 [INFO] Testing combination 23/150: {'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 7
Epoch    11: reducing learning rate of group 0 to 1.0000e-04.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 13
Epoch    17: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 18
Epoch    22: reducing learning rate of group 0 to 1.0000e-06.
2024-10-05 18:32:04,156 [INFO] curr best accuracy: 88.62, params: {'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}
2024-10-05 18:32:04,156 [INFO] Testing combination 24/150: {'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 4
Epoch     8: reducing learning rate of group 0 to 1.0000e-04.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 17
Epoch    21: reducing learning rate of group 0 to 1.0000e-05.
Epoch    25: reducing learning rate of group 0 to 1.0000e-06.
2024-10-05 18:33:12,089 [INFO] curr best accuracy: 89.08, params: {'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}
2024-10-05 18:33:12,090 [INFO] Testing combination 25/150: {'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 17
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 19
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 20
Epoch    24: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 25
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 26
Epoch    30: reducing learning rate of group 0 to 1.0000e-06.
Epoch    34: reducing learning rate of group 0 to 1.0000e-07.
2024-10-05 18:36:59,816 [INFO] curr best accuracy: 88.56, params: {'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}
2024-10-05 18:36:59,817 [INFO] Testing combination 26/150: {'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 14
Epoch    18: reducing learning rate of group 0 to 1.0000e-04.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 19
Epoch    23: reducing learning rate of group 0 to 1.0000e-05.
Epoch    27: reducing learning rate of group 0 to 1.0000e-06.
2024-10-05 18:38:11,191 [INFO] curr best accuracy: 89.08, params: {'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}
2024-10-05 18:38:11,191 [INFO] Testing combination 27/150: {'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 19
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 20
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 22
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 25
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 28
Epoch    32: reducing learning rate of group 0 to 1.0000e-04.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 33
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 34
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 37
Epoch    41: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 42
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 44
Epoch    48: reducing learning rate of group 0 to 1.0000e-06.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 49
Epoch    53: reducing learning rate of group 0 to 1.0000e-07.
Epoch    57: reducing learning rate of group 0 to 1.0000e-08.
2024-10-05 18:41:56,415 [INFO] curr best accuracy: 89.38, params: {'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}
2024-10-05 18:41:56,415 [INFO] Testing combination 28/150: {'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 15
Epoch    19: reducing learning rate of group 0 to 1.0000e-04.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 20
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 22
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 26
Epoch    30: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 31
Epoch    35: reducing learning rate of group 0 to 1.0000e-06.
2024-10-05 18:42:59,371 [INFO] curr best accuracy: 89.8, params: {'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}
2024-10-05 18:42:59,372 [INFO] New best accuracy: 89.8, params: {'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}
2024-10-05 18:42:59,372 [INFO] Testing combination 29/150: {'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 16
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 17
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 19
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 21
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 23
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 24
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 25
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 27
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 28
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 31
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 33
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 34
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 37
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 38
Epoch    42: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 43
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 44
Epoch    48: reducing learning rate of group 0 to 1.0000e-06.
2024-10-05 18:44:45,842 [INFO] curr best accuracy: 88.46, params: {'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}
2024-10-05 18:44:45,842 [INFO] Testing combination 30/150: {'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 8
Epoch    12: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 18
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 20
Epoch    24: reducing learning rate of group 0 to 1.0000e-06.
2024-10-05 18:47:27,860 [INFO] curr best accuracy: 89.28, params: {'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}
2024-10-05 18:47:27,861 [INFO] Testing combination 31/150: {'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 18
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 20
Epoch    24: reducing learning rate of group 0 to 1.0000e-04.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 25
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 27
Epoch    31: reducing learning rate of group 0 to 1.0000e-05.
Epoch    35: reducing learning rate of group 0 to 1.0000e-06.
2024-10-05 18:49:34,935 [INFO] curr best accuracy: 88.34, params: {'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}
2024-10-05 18:49:34,936 [INFO] Testing combination 32/150: {'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 16
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 18
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 19
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 20
Epoch    24: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 25
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 26
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 28
Epoch    32: reducing learning rate of group 0 to 1.0000e-06.
2024-10-05 18:50:31,677 [INFO] curr best accuracy: 87.6, params: {'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}
2024-10-05 18:50:31,677 [INFO] Testing combination 33/150: {'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 16
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 18
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 21
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 25
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 26
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 28
Epoch    32: reducing learning rate of group 0 to 1.0000e-04.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 33
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 34
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 38
Epoch    42: reducing learning rate of group 0 to 1.0000e-05.
Epoch    46: reducing learning rate of group 0 to 1.0000e-06.
2024-10-05 18:51:52,429 [INFO] curr best accuracy: 88.54, params: {'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}
2024-10-05 18:51:52,430 [INFO] Testing combination 34/150: {'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 17
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 18
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 22
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 26
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 28
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 30
Epoch    34: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 35
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 36
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 37
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 41
Epoch    45: reducing learning rate of group 0 to 1.0000e-06.
Epoch    49: reducing learning rate of group 0 to 1.0000e-07.
2024-10-05 18:54:48,252 [INFO] curr best accuracy: 89.12, params: {'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}
2024-10-05 18:54:48,253 [INFO] Testing combination 35/150: {'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 16
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 17
Epoch    21: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 22
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 24
Epoch    28: reducing learning rate of group 0 to 1.0000e-06.
2024-10-05 18:56:29,690 [INFO] curr best accuracy: 87.76, params: {'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}
2024-10-05 18:56:29,691 [INFO] Testing combination 36/150: {'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 7
Epoch    11: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 15
Epoch    19: reducing learning rate of group 0 to 1.0000e-06.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 21
Epoch    25: reducing learning rate of group 0 to 1.0000e-07.
Epoch    29: reducing learning rate of group 0 to 1.0000e-08.
2024-10-05 18:58:30,860 [INFO] curr best accuracy: 89.3, params: {'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}
2024-10-05 18:58:30,861 [INFO] Testing combination 37/150: {'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 4
Epoch     8: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 9
Epoch    13: reducing learning rate of group 0 to 1.0000e-06.
Epoch    17: reducing learning rate of group 0 to 1.0000e-07.
2024-10-05 18:59:18,948 [INFO] curr best accuracy: 89.6, params: {'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}
2024-10-05 18:59:18,948 [INFO] Testing combination 38/150: {'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 16
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 18
Epoch    22: reducing learning rate of group 0 to 1.0000e-04.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 23
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 24
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 28
Epoch    32: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 33
Epoch    37: reducing learning rate of group 0 to 1.0000e-06.
2024-10-05 19:00:42,671 [INFO] curr best accuracy: 88.96, params: {'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}
2024-10-05 19:00:42,672 [INFO] Testing combination 39/150: {'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 9
Epoch    13: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 17
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 21
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 22
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 23
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 26
Epoch    30: reducing learning rate of group 0 to 1.0000e-06.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 32
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 34
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 38
Epoch    42: reducing learning rate of group 0 to 1.0000e-07.
Epoch    46: reducing learning rate of group 0 to 1.0000e-08.
2024-10-05 19:03:48,569 [INFO] curr best accuracy: 89.4, params: {'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}
2024-10-05 19:03:48,569 [INFO] Testing combination 40/150: {'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 9
Epoch    13: reducing learning rate of group 0 to 1.0000e-04.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 16
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 17
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 19
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 22
Epoch    26: reducing learning rate of group 0 to 1.0000e-05.
Epoch    30: reducing learning rate of group 0 to 1.0000e-06.
2024-10-05 19:05:00,077 [INFO] curr best accuracy: 88.64, params: {'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}
2024-10-05 19:05:00,077 [INFO] Testing combination 41/150: {'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 12
Epoch    16: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 17
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 19
Epoch    23: reducing learning rate of group 0 to 1.0000e-06.
Epoch    27: reducing learning rate of group 0 to 1.0000e-07.
2024-10-05 19:06:41,815 [INFO] curr best accuracy: 88.22, params: {'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}
2024-10-05 19:06:41,816 [INFO] Testing combination 42/150: {'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 12
Epoch    16: reducing learning rate of group 0 to 1.0000e-04.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 17
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 18
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 20
Epoch    24: reducing learning rate of group 0 to 1.0000e-05.
2024-10-05 19:08:09,644 [INFO] curr best accuracy: 87.54, params: {'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}
2024-10-05 19:08:09,645 [INFO] Testing combination 43/150: {'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 15
Epoch    19: reducing learning rate of group 0 to 1.0000e-04.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 20
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 21
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 23
Epoch    27: reducing learning rate of group 0 to 1.0000e-05.
Epoch    31: reducing learning rate of group 0 to 1.0000e-06.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 33
Epoch    37: reducing learning rate of group 0 to 1.0000e-07.
Epoch    41: reducing learning rate of group 0 to 1.0000e-08.
2024-10-05 19:09:56,414 [INFO] curr best accuracy: 88.7, params: {'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}
2024-10-05 19:09:56,414 [INFO] Testing combination 44/150: {'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 17
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 19
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 22
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 25
Epoch    29: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 30
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 31
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 32
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 36
Epoch    40: reducing learning rate of group 0 to 1.0000e-06.
Epoch    44: reducing learning rate of group 0 to 1.0000e-07.
2024-10-05 19:12:54,914 [INFO] curr best accuracy: 89.18, params: {'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}
2024-10-05 19:12:54,914 [INFO] Testing combination 45/150: {'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 17
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 18
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 19
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 20
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 23
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 26
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 27
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 30
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 31
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 32
Epoch    36: reducing learning rate of group 0 to 1.0000e-04.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 37
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 38
Epoch    42: reducing learning rate of group 0 to 1.0000e-05.
Epoch    46: reducing learning rate of group 0 to 1.0000e-06.
2024-10-05 19:16:59,100 [INFO] curr best accuracy: 87.64, params: {'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}
2024-10-05 19:16:59,101 [INFO] Testing combination 46/150: {'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 17
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 18
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 19
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 20
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 21
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 25
Epoch    29: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 30
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 32
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 35
Epoch    39: reducing learning rate of group 0 to 1.0000e-06.
Epoch    43: reducing learning rate of group 0 to 1.0000e-07.
2024-10-05 19:18:37,493 [INFO] curr best accuracy: 88.48, params: {'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}
2024-10-05 19:18:37,494 [INFO] Testing combination 47/150: {'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 10
Epoch    14: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 17
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 21
Epoch    25: reducing learning rate of group 0 to 1.0000e-06.
Epoch    29: reducing learning rate of group 0 to 1.0000e-07.
2024-10-05 19:20:28,246 [INFO] curr best accuracy: 89.0, params: {'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}
2024-10-05 19:20:28,246 [INFO] Testing combination 48/150: {'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 18
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 20
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 21
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 22
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 23
Epoch    27: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 28
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 29
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 31
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 35
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 38
Epoch    42: reducing learning rate of group 0 to 1.0000e-06.
Epoch    46: reducing learning rate of group 0 to 1.0000e-07.
2024-10-05 19:25:00,279 [INFO] curr best accuracy: 89.36, params: {'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}
2024-10-05 19:25:00,280 [INFO] Testing combination 49/150: {'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 18
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 22
Epoch    26: reducing learning rate of group 0 to 1.0000e-04.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 27
Epoch    31: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 32
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 34
Epoch    38: reducing learning rate of group 0 to 1.0000e-06.
Epoch    42: reducing learning rate of group 0 to 1.0000e-07.
2024-10-05 19:26:49,098 [INFO] curr best accuracy: 89.16, params: {'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}
2024-10-05 19:26:49,099 [INFO] Testing combination 50/150: {'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 14
Epoch    18: reducing learning rate of group 0 to 1.0000e-04.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 19
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 20
Epoch    24: reducing learning rate of group 0 to 1.0000e-05.
Epoch    28: reducing learning rate of group 0 to 1.0000e-06.
2024-10-05 19:28:48,594 [INFO] curr best accuracy: 89.54, params: {'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}
2024-10-05 19:28:48,594 [INFO] Testing combination 51/150: {'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 16
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 17
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 19
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 21
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 22
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 24
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 25
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 27
Epoch    31: reducing learning rate of group 0 to 1.0000e-04.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 32
Epoch    36: reducing learning rate of group 0 to 1.0000e-05.
Epoch    40: reducing learning rate of group 0 to 1.0000e-06.
2024-10-05 19:30:01,545 [INFO] curr best accuracy: 88.82, params: {'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}
2024-10-05 19:30:01,546 [INFO] Testing combination 52/150: {'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 16
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 17
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 18
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 19
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 20
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 21
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 22
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 23
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 24
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 25
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 26
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 27
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 29
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 30
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 31
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 33
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 34
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 35
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 36
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 37
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 38
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 39
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 40
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 42
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 43
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 44
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 45
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 47
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 48
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 49
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 50
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 51
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 53
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 54
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 55
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 57
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 58
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 59
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 60
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 61
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 62
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 63
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 64
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 65
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 67
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 68
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 69
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 70
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 71
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 72
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 73
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 74
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 75
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 76
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 78
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 80
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 82
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 84
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 85
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 87
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 89
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 90
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 92
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 94
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 95
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 97
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 98
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 99
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 100
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 102
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 105
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 106
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 109
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 110
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 112
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 113
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 114
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 118
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 120
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 121
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 124
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 125
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 127
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 129
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 130
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 131
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 132
Epoch   136: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 137
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 138
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 140
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 141
Epoch   145: reducing learning rate of group 0 to 1.0000e-06.
2024-10-05 19:34:10,154 [INFO] curr best accuracy: 81.2, params: {'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}
2024-10-05 19:34:10,155 [INFO] Testing combination 53/150: {'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 9
Epoch    13: reducing learning rate of group 0 to 1.0000e-04.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 15
Epoch    19: reducing learning rate of group 0 to 1.0000e-05.
Epoch    23: reducing learning rate of group 0 to 1.0000e-06.
2024-10-05 19:35:12,881 [INFO] curr best accuracy: 89.14, params: {'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}
2024-10-05 19:35:12,881 [INFO] Testing combination 54/150: {'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 16
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 17
Epoch    21: reducing learning rate of group 0 to 1.0000e-04.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 22
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 23
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 24
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 27
Epoch    31: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 32
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 35
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 37
Epoch    41: reducing learning rate of group 0 to 1.0000e-06.
2024-10-05 19:37:39,245 [INFO] curr best accuracy: 88.66, params: {'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}
2024-10-05 19:37:39,245 [INFO] Testing combination 55/150: {'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 16
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 17
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 18
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 20
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 21
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 22
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 24
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 25
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 26
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 27
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 29
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 33
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 36
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 38
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 41
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 44
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 46
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 48
Epoch    52: reducing learning rate of group 0 to 1.0000e-04.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 53
Epoch    57: reducing learning rate of group 0 to 1.0000e-05.
Epoch    61: reducing learning rate of group 0 to 1.0000e-06.
2024-10-05 19:40:51,327 [INFO] curr best accuracy: 87.64, params: {'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}
2024-10-05 19:40:51,329 [INFO] Testing combination 56/150: {'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 16
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 17
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 18
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 19
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 20
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 21
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 22
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 23
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 24
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 25
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 26
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 27
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 28
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 29
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 30
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 31
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 32
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 33
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 34
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 35
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 36
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 37
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 38
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 39
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 40
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 41
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 42
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 43
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 45
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 47
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 48
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 49
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 51
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 52
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 54
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 55
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 56
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 57
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 58
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 59
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 60
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 61
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 62
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 63
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 64
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 65
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 67
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 68
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 69
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 70
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 71
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 72
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 74
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 76
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 77
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 80
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 81
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 82
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 83
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 84
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 85
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 86
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 87
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 88
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 90
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 91
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 92
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 96
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 98
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 99
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 100
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 101
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 102
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 103
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 104
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 107
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 109
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 110
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 111
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 113
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 114
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 118
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 119
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 120
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 124
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 125
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 128
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 129
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 132
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 135
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 137
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 139
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 140
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 141
Epoch   145: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 146
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 147
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 149
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 150
Epoch   154: reducing learning rate of group 0 to 1.0000e-06.
Epoch   158: reducing learning rate of group 0 to 1.0000e-07.
2024-10-05 19:44:55,809 [INFO] curr best accuracy: 80.22, params: {'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}
2024-10-05 19:44:55,810 [INFO] Testing combination 57/150: {'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 17
Epoch    21: reducing learning rate of group 0 to 1.0000e-04.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 22
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 24
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 26
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 30
Epoch    34: reducing learning rate of group 0 to 1.0000e-05.
Epoch    38: reducing learning rate of group 0 to 1.0000e-06.
2024-10-05 19:46:04,707 [INFO] curr best accuracy: 89.42, params: {'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}
2024-10-05 19:46:04,708 [INFO] Testing combination 58/150: {'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 15
Epoch    19: reducing learning rate of group 0 to 1.0000e-04.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 20
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 23
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 27
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 28
Epoch    32: reducing learning rate of group 0 to 1.0000e-05.
Epoch    36: reducing learning rate of group 0 to 1.0000e-06.
2024-10-05 19:48:15,913 [INFO] curr best accuracy: 89.04, params: {'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}
2024-10-05 19:48:15,914 [INFO] Testing combination 59/150: {'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 4
Epoch     8: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 9
Epoch    13: reducing learning rate of group 0 to 1.0000e-06.
Epoch    17: reducing learning rate of group 0 to 1.0000e-07.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 19
Epoch    23: reducing learning rate of group 0 to 1.0000e-08.
2024-10-05 19:50:10,020 [INFO] curr best accuracy: 89.44, params: {'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}
2024-10-05 19:50:10,020 [INFO] Testing combination 60/150: {'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 16
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 17
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 18
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 19
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 20
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 22
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 23
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 24
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 25
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 27
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 28
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 29
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 30
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 31
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 32
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 33
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 34
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 36
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 37
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 39
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 42
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 44
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 46
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 47
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 49
Epoch    53: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 54
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 55
Epoch    59: reducing learning rate of group 0 to 1.0000e-06.
Epoch    63: reducing learning rate of group 0 to 1.0000e-07.
2024-10-05 19:56:06,795 [INFO] curr best accuracy: 84.5, params: {'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}
2024-10-05 19:56:06,795 [INFO] Testing combination 61/150: {'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 6
Epoch    10: reducing learning rate of group 0 to 1.0000e-04.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 15
Epoch    19: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 20
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 21
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 22
Epoch    26: reducing learning rate of group 0 to 1.0000e-06.
2024-10-05 19:56:56,334 [INFO] curr best accuracy: 89.02, params: {'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}
2024-10-05 19:56:56,334 [INFO] Testing combination 62/150: {'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 16
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 17
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 18
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 19
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 22
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 24
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 25
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 26
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 27
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 29
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 32
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 33
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 34
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 37
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 40
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 43
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 44
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 48
Epoch    52: reducing learning rate of group 0 to 1.0000e-05.
2024-10-05 19:58:23,226 [INFO] curr best accuracy: 88.2, params: {'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}
2024-10-05 19:58:23,227 [INFO] Testing combination 63/150: {'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 10
Epoch    14: reducing learning rate of group 0 to 1.0000e-04.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 15
Epoch    19: reducing learning rate of group 0 to 1.0000e-05.
2024-10-05 19:59:07,641 [INFO] curr best accuracy: 88.74, params: {'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}
2024-10-05 19:59:07,641 [INFO] Testing combination 64/150: {'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 7
Epoch    11: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 13
Epoch    17: reducing learning rate of group 0 to 1.0000e-06.
2024-10-05 20:00:10,912 [INFO] curr best accuracy: 88.72, params: {'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}
2024-10-05 20:00:10,913 [INFO] Testing combination 65/150: {'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 7
Epoch    11: reducing learning rate of group 0 to 1.0000e-04.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 17
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 20
Epoch    24: reducing learning rate of group 0 to 1.0000e-05.
Epoch    28: reducing learning rate of group 0 to 1.0000e-06.
2024-10-05 20:02:06,707 [INFO] curr best accuracy: 88.94, params: {'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}
2024-10-05 20:02:06,708 [INFO] Testing combination 66/150: {'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 7
Epoch    11: reducing learning rate of group 0 to 1.0000e-04.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 19
Epoch    23: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 25
Epoch    29: reducing learning rate of group 0 to 1.0000e-06.
Epoch    33: reducing learning rate of group 0 to 1.0000e-07.
2024-10-05 20:05:43,823 [INFO] curr best accuracy: 88.86, params: {'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}
2024-10-05 20:05:43,824 [INFO] Testing combination 67/150: {'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 4
Epoch     8: reducing learning rate of group 0 to 1.0000e-04.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 17
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 18
Epoch    22: reducing learning rate of group 0 to 1.0000e-05.
Epoch    26: reducing learning rate of group 0 to 1.0000e-06.
2024-10-05 20:08:22,560 [INFO] curr best accuracy: 89.08, params: {'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}
2024-10-05 20:08:22,561 [INFO] Testing combination 68/150: {'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 18
Epoch    22: reducing learning rate of group 0 to 1.0000e-04.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 23
Epoch    27: reducing learning rate of group 0 to 1.0000e-05.
Epoch    31: reducing learning rate of group 0 to 1.0000e-06.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 33
Epoch    37: reducing learning rate of group 0 to 1.0000e-07.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 41
Epoch    45: reducing learning rate of group 0 to 1.0000e-08.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 51
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 54
2024-10-05 20:14:27,531 [INFO] curr best accuracy: 88.78, params: {'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}
2024-10-05 20:14:27,532 [INFO] Testing combination 69/150: {'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 14
Epoch    18: reducing learning rate of group 0 to 1.0000e-04.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 19
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 20
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 21
Epoch    25: reducing learning rate of group 0 to 1.0000e-05.
2024-10-05 20:15:57,543 [INFO] curr best accuracy: 88.12, params: {'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}
2024-10-05 20:15:57,544 [INFO] Testing combination 70/150: {'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 7
Epoch    11: reducing learning rate of group 0 to 1.0000e-04.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 16
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 20
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 24
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 28
Epoch    32: reducing learning rate of group 0 to 1.0000e-05.
2024-10-05 20:19:06,150 [INFO] curr best accuracy: 88.4, params: {'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}
2024-10-05 20:19:06,151 [INFO] Testing combination 71/150: {'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 5
Epoch     9: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 10
Epoch    14: reducing learning rate of group 0 to 1.0000e-06.
2024-10-05 20:19:44,522 [INFO] curr best accuracy: 89.38, params: {'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}
2024-10-05 20:19:44,522 [INFO] Testing combination 72/150: {'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 17
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 18
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 20
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 22
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 24
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 27
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 28
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 29
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 30
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 31
Epoch    35: reducing learning rate of group 0 to 1.0000e-04.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 37
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 40
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 42
Epoch    46: reducing learning rate of group 0 to 1.0000e-05.
Epoch    50: reducing learning rate of group 0 to 1.0000e-06.
2024-10-05 20:22:21,770 [INFO] curr best accuracy: 86.38, params: {'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}
2024-10-05 20:22:21,770 [INFO] Testing combination 73/150: {'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 16
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 17
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 18
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 19
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 20
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 21
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 22
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 23
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 24
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 25
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 26
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 27
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 28
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 30
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 31
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 32
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 33
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 34
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 35
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 36
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 37
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 38
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 39
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 40
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 41
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 42
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 43
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 44
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 45
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 47
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 49
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 50
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 51
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 52
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 53
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 55
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 56
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 59
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 63
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 66
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 69
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 71
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 74
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 75
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 77
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 78
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 79
Epoch    83: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 85
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 86
Epoch    90: reducing learning rate of group 0 to 1.0000e-06.
Epoch    94: reducing learning rate of group 0 to 1.0000e-07.
2024-10-05 20:30:29,636 [INFO] curr best accuracy: 84.36, params: {'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}
2024-10-05 20:30:29,636 [INFO] Testing combination 74/150: {'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 16
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 17
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 19
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 22
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 25
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 27
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 28
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 30
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 33
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 35
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 38
Epoch    42: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 43
Epoch    47: reducing learning rate of group 0 to 1.0000e-06.
Epoch    51: reducing learning rate of group 0 to 1.0000e-07.
2024-10-05 20:32:26,968 [INFO] curr best accuracy: 89.22, params: {'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}
2024-10-05 20:32:26,969 [INFO] Testing combination 75/150: {'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 13
Epoch    17: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 18
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 19
Epoch    23: reducing learning rate of group 0 to 1.0000e-06.
Epoch    27: reducing learning rate of group 0 to 1.0000e-07.
2024-10-05 20:33:33,785 [INFO] curr best accuracy: 88.56, params: {'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}
2024-10-05 20:33:33,785 [INFO] Testing combination 76/150: {'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 16
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 17
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 18
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 19
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 20
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 21
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 22
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 23
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 24
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 25
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 27
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 28
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 29
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 30
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 31
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 32
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 34
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 35
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 36
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 37
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 38
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 40
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 41
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 43
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 45
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 47
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 48
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 50
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 51
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 52
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 53
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 54
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 56
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 57
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 61
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 62
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 64
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 68
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 71
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 72
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 75
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 77
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 81
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 85
Epoch    89: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 90
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 91
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 92
Epoch    96: reducing learning rate of group 0 to 1.0000e-06.
2024-10-05 20:42:39,016 [INFO] curr best accuracy: 87.68, params: {'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}
2024-10-05 20:42:39,017 [INFO] Testing combination 77/150: {'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 1
Epoch     5: reducing learning rate of group 0 to 1.0000e-04.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 6
Epoch    10: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 12
Epoch    16: reducing learning rate of group 0 to 1.0000e-06.
2024-10-05 20:43:24,123 [INFO] curr best accuracy: 89.26, params: {'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}
2024-10-05 20:43:24,123 [INFO] Testing combination 78/150: {'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 16
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 17
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 18
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 19
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 20
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 21
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 24
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 26
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 27
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 29
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 30
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 31
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 33
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 37
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 39
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 41
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 42
Epoch    46: reducing learning rate of group 0 to 1.0000e-04.
2024-10-05 20:45:46,909 [INFO] curr best accuracy: 86.52, params: {'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}
2024-10-05 20:45:46,910 [INFO] Testing combination 79/150: {'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 16
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 17
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 18
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 19
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 20
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 22
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 23
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 24
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 25
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 26
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 27
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 28
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 29
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 30
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 31
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 32
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 33
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 34
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 35
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 36
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 37
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 38
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 39
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 40
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 42
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 43
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 44
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 47
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 49
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 50
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 51
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 54
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 55
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 56
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 57
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 59
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 60
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 61
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 65
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 66
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 67
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 69
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 70
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 73
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 74
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 75
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 76
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 77
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 78
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 79
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 80
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 81
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 83
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 84
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 87
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 89
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 90
Epoch    94: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 95
Epoch    99: reducing learning rate of group 0 to 1.0000e-06.
2024-10-05 20:48:34,832 [INFO] curr best accuracy: 85.82, params: {'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}
2024-10-05 20:48:34,832 [INFO] Testing combination 80/150: {'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 16
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 18
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 19
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 20
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 21
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 22
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 23
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 24
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 25
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 26
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 27
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 28
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 29
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 30
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 31
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 32
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 33
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 34
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 35
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 36
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 37
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 38
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 39
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 40
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 41
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 42
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 43
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 44
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 45
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 46
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 47
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 48
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 49
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 50
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 52
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 53
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 54
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 55
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 56
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 57
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 58
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 59
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 60
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 62
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 64
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 65
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 66
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 68
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 69
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 70
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 71
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 74
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 75
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 76
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 77
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 78
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 79
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 80
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 81
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 82
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 83
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 84
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 85
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 86
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 87
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 88
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 89
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 90
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 91
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 92
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 93
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 94
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 95
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 98
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 99
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 101
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 102
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 106
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 108
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 110
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 112
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 113
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 114
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 118
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 119
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 120
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 122
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 123
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 124
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 125
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 128
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 130
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 131
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 132
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 134
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 137
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 138
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 139
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 140
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 143
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 145
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 146
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 147
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 150
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 154
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 155
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 157
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 158
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 160
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 163
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 165
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 167
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 169
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 170
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 172
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 174
Epoch   178: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 179
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 180
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 182
Epoch   186: reducing learning rate of group 0 to 1.0000e-06.
2024-10-05 20:53:48,878 [INFO] curr best accuracy: 80.44, params: {'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 5}
2024-10-05 20:53:48,878 [INFO] Testing combination 81/150: {'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 32, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 32, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 32, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 32, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 32, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 32, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 32, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 32, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 13
Epoch    17: reducing learning rate of group 0 to 1.0000e-04.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 32, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 18
Epoch    22: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 32, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 23
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 32, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 24
Epoch    28: reducing learning rate of group 0 to 1.0000e-06.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 32, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 32
Epoch    36: reducing learning rate of group 0 to 1.0000e-07.
Epoch    40: reducing learning rate of group 0 to 1.0000e-08.
2024-10-05 20:57:43,403 [INFO] curr best accuracy: 88.74, params: {'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 32, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}
2024-10-05 20:57:43,403 [INFO] Testing combination 82/150: {'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 7
Epoch    11: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 17
Epoch    21: reducing learning rate of group 0 to 1.0000e-06.
Epoch    25: reducing learning rate of group 0 to 1.0000e-07.
2024-10-05 20:58:51,815 [INFO] curr best accuracy: 89.24, params: {'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}
2024-10-05 20:58:51,815 [INFO] Testing combination 83/150: {'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 4
Epoch     8: reducing learning rate of group 0 to 1.0000e-04.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 10
Epoch    14: reducing learning rate of group 0 to 1.0000e-05.
Epoch    18: reducing learning rate of group 0 to 1.0000e-06.
2024-10-05 20:59:28,228 [INFO] curr best accuracy: 89.3, params: {'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}
2024-10-05 20:59:28,228 [INFO] Testing combination 84/150: {'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 10
Epoch    14: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 16
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 18
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 19
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 22
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 25
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 27
Epoch    31: reducing learning rate of group 0 to 1.0000e-06.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 32
Epoch    36: reducing learning rate of group 0 to 1.0000e-07.
2024-10-05 21:03:19,098 [INFO] curr best accuracy: 89.04, params: {'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}
2024-10-05 21:03:19,098 [INFO] Testing combination 85/150: {'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 16
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 17
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 18
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 19
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 20
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 21
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 22
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 23
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 24
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 25
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 27
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 28
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 29
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 30
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 31
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 32
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 33
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 34
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 37
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 38
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 39
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 41
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 44
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 45
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 48
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 49
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 51
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 52
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 54
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 55
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 56
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 57
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 58
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 60
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 62
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 63
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 65
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 67
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 68
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 69
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 72
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 73
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 76
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 77
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 78
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 80
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 81
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 84
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 87
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 89
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 90
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 93
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 94
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 95
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 97
Epoch   101: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 102
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 103
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 104
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 105
Epoch   109: reducing learning rate of group 0 to 1.0000e-06.
2024-10-05 21:12:29,681 [INFO] curr best accuracy: 83.6, params: {'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}
2024-10-05 21:12:29,682 [INFO] Testing combination 86/150: {'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 9
Epoch    13: reducing learning rate of group 0 to 1.0000e-04.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 18
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 20
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 22
Epoch    26: reducing learning rate of group 0 to 1.0000e-05.
2024-10-05 21:14:05,103 [INFO] curr best accuracy: 88.78, params: {'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}
2024-10-05 21:14:05,104 [INFO] Testing combination 87/150: {'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 16
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 17
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 18
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 19
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 20
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 21
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 22
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 23
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 24
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 25
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 27
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 28
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 29
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 31
Epoch    35: reducing learning rate of group 0 to 1.0000e-04.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 36
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 37
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 38
Epoch    42: reducing learning rate of group 0 to 1.0000e-05.
Epoch    46: reducing learning rate of group 0 to 1.0000e-06.
2024-10-05 21:15:41,305 [INFO] curr best accuracy: 87.12, params: {'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}
2024-10-05 21:15:41,305 [INFO] Testing combination 88/150: {'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 3
Epoch     7: reducing learning rate of group 0 to 1.0000e-05.
Epoch    11: reducing learning rate of group 0 to 1.0000e-06.
2024-10-05 21:16:04,055 [INFO] curr best accuracy: 35.42, params: {'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}
2024-10-05 21:16:04,055 [INFO] Testing combination 89/150: {'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 4
Epoch     8: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 9
Epoch    13: reducing learning rate of group 0 to 1.0000e-06.
Epoch    17: reducing learning rate of group 0 to 1.0000e-07.
2024-10-05 21:16:39,625 [INFO] curr best accuracy: 89.4, params: {'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}
2024-10-05 21:16:39,625 [INFO] Testing combination 90/150: {'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 16
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 17
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 18
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 19
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 20
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 21
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 22
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 23
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 24
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 25
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 26
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 27
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 28
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 29
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 30
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 31
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 32
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 33
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 34
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 35
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 36
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 37
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 38
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 39
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 40
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 41
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 42
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 43
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 44
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 45
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 46
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 47
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 48
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 49
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 50
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 52
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 53
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 54
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 55
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 56
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 58
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 59
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 60
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 61
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 62
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 63
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 64
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 65
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 66
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 67
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 68
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 69
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 71
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 72
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 73
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 74
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 75
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 76
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 77
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 78
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 80
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 83
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 84
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 85
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 87
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 88
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 90
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 91
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 93
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 94
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 95
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 96
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 100
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 103
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 106
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 109
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 110
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 112
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 113
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 114
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 115
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 117
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 120
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 121
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 122
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 123
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 124
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 125
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 127
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 128
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 130
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 131
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 133
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 134
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 136
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 137
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 138
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 139
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 140
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 142
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 144
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 145
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 146
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 147
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 149
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 153
Epoch   157: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 158
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 159
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 162
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 164
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 166
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 170
Epoch   174: reducing learning rate of group 0 to 1.0000e-06.
Epoch   178: reducing learning rate of group 0 to 1.0000e-07.
2024-10-05 21:21:10,349 [INFO] curr best accuracy: 79.58, params: {'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}
2024-10-05 21:21:10,349 [INFO] Testing combination 91/150: {'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 16
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 17
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 18
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 19
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 21
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 23
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 25
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 26
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 27
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 31
Epoch    35: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 36
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 40
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 44
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 46
Epoch    50: reducing learning rate of group 0 to 1.0000e-06.
2024-10-05 21:22:32,846 [INFO] curr best accuracy: 88.92, params: {'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}
2024-10-05 21:22:32,846 [INFO] Testing combination 92/150: {'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 18
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 19
Epoch    23: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 24
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 25
Epoch    29: reducing learning rate of group 0 to 1.0000e-06.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 32
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 36
Epoch    40: reducing learning rate of group 0 to 1.0000e-07.
Epoch    44: reducing learning rate of group 0 to 1.0000e-08.
2024-10-05 21:25:11,778 [INFO] curr best accuracy: 87.3, params: {'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}
2024-10-05 21:25:11,779 [INFO] Testing combination 93/150: {'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 11
Epoch    15: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 16
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 17
Epoch    21: reducing learning rate of group 0 to 1.0000e-06.
2024-10-05 21:27:31,037 [INFO] curr best accuracy: 89.12, params: {'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}
2024-10-05 21:27:31,037 [INFO] Testing combination 94/150: {'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 16
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 17
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 18
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 19
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 20
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 21
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 22
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 23
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 25
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 26
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 27
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 28
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 29
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 30
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 31
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 32
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 33
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 34
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 35
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 36
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 37
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 38
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 39
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 40
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 41
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 42
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 44
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 45
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 47
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 48
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 49
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 51
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 53
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 57
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 58
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 61
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 64
Epoch    68: reducing learning rate of group 0 to 1.0000e-04.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 69
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 72
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 75
Epoch    79: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 82
Epoch    86: reducing learning rate of group 0 to 1.0000e-06.
Epoch    90: reducing learning rate of group 0 to 1.0000e-07.
2024-10-05 21:29:50,531 [INFO] curr best accuracy: 84.98, params: {'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}
2024-10-05 21:29:50,532 [INFO] Testing combination 95/150: {'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 16
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 17
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 18
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 19
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 20
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 21
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 22
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 23
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 24
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 25
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 26
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 28
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 29
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 30
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 31
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 32
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 33
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 34
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 35
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 37
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 38
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 40
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 41
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 43
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 45
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 47
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 48
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 49
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 50
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 51
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 52
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 53
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 54
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 56
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 58
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 60
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 61
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 62
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 64
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 66
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 68
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 71
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 74
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 75
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 76
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 77
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 79
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 80
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 81
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 83
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 85
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 87
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 88
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 89
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 92
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 93
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 94
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 98
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 99
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 100
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 103
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 105
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 107
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 108
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 109
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 111
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 115
Epoch   119: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 120
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 121
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 123
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 124
Epoch   128: reducing learning rate of group 0 to 1.0000e-06.
2024-10-05 21:40:25,434 [INFO] curr best accuracy: 83.52, params: {'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}
2024-10-05 21:40:25,435 [INFO] Testing combination 96/150: {'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 16
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 18
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 19
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 21
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 22
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 23
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 24
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 25
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 26
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 28
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 29
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 30
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 31
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 32
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 33
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 34
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 35
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 36
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 37
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 38
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 39
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 40
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 41
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 42
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 43
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 44
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 47
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 49
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 50
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 51
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 52
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 54
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 56
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 57
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 58
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 59
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 60
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 61
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 62
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 64
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 65
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 66
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 67
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 68
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 69
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 70
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 72
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 73
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 74
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 76
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 79
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 82
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 85
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 86
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 89
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 91
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 93
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 94
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 97
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 100
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 103
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 105
Epoch   109: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 111
Epoch   115: reducing learning rate of group 0 to 1.0000e-06.
Epoch   119: reducing learning rate of group 0 to 1.0000e-07.
2024-10-05 21:44:41,667 [INFO] curr best accuracy: 84.14, params: {'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}
2024-10-05 21:44:41,668 [INFO] Testing combination 97/150: {'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 9
Epoch    13: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 17
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 21
Epoch    25: reducing learning rate of group 0 to 1.0000e-06.
2024-10-05 21:46:13,194 [INFO] curr best accuracy: 88.38, params: {'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}
2024-10-05 21:46:13,195 [INFO] Testing combination 98/150: {'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 12
Epoch    16: reducing learning rate of group 0 to 1.0000e-04.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 17
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 18
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 20
Epoch    24: reducing learning rate of group 0 to 1.0000e-05.
Epoch    28: reducing learning rate of group 0 to 1.0000e-06.
2024-10-05 21:47:58,141 [INFO] curr best accuracy: 87.54, params: {'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}
2024-10-05 21:47:58,141 [INFO] Testing combination 99/150: {'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 17
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 19
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 20
Epoch    24: reducing learning rate of group 0 to 1.0000e-04.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 25
Epoch    29: reducing learning rate of group 0 to 1.0000e-05.
Epoch    33: reducing learning rate of group 0 to 1.0000e-06.
2024-10-05 21:49:42,190 [INFO] curr best accuracy: 85.22, params: {'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}
2024-10-05 21:49:42,190 [INFO] Testing combination 100/150: {'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 6
Epoch    10: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 13
Epoch    17: reducing learning rate of group 0 to 1.0000e-06.
Epoch    21: reducing learning rate of group 0 to 1.0000e-07.
2024-10-05 21:51:02,736 [INFO] curr best accuracy: 88.68, params: {'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}
2024-10-05 21:51:02,736 [INFO] Testing combination 101/150: {'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 16
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 17
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 18
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 19
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 20
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 21
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 22
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 23
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 24
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 25
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 26
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 27
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 28
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 29
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 30
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 31
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 32
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 33
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 34
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 35
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 36
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 37
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 38
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 39
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 40
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 42
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 45
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 48
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 49
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 50
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 52
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 53
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 55
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 57
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 58
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 59
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 61
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 62
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 64
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 66
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 67
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 68
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 69
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 71
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 73
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 74
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 75
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 76
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 77
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 78
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 79
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 80
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 81
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 83
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 84
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 86
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 88
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 89
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 90
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 92
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 94
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 95
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 96
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 97
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 98
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 101
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 102
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 104
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 106
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 109
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 110
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 112
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 116
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 117
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 121
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 125
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 128
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 130
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 133
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 137
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 140
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 141
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 145
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 147
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 148
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 149
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 151
Epoch   155: reducing learning rate of group 0 to 1.0000e-05.
2024-10-05 21:54:57,840 [INFO] curr best accuracy: 80.08, params: {'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}
2024-10-05 21:54:57,840 [INFO] Testing combination 102/150: {'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 16
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 17
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 18
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 19
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 21
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 25
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 26
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 27
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 28
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 29
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 32
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 33
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 34
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 35
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 36
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 37
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 39
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 40
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 41
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 42
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 44
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 45
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 46
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 47
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 48
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 50
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 52
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 53
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 54
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 56
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 58
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 60
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 62
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 63
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 65
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 66
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 68
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 70
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 73
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 74
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 76
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 77
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 78
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 79
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 81
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 82
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 83
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 85
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 87
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 89
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 91
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 93
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 95
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 96
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 99
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 100
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 104
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 106
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 110
Epoch   114: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 115
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 116
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 119
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 121
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 125
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 129
Epoch   133: reducing learning rate of group 0 to 1.0000e-06.
2024-10-05 21:58:27,339 [INFO] curr best accuracy: 78.96, params: {'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}
2024-10-05 21:58:27,339 [INFO] Testing combination 103/150: {'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 17
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 20
Epoch    24: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 25
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 28
Epoch    32: reducing learning rate of group 0 to 1.0000e-06.
2024-10-05 22:01:35,745 [INFO] curr best accuracy: 89.18, params: {'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}
2024-10-05 22:01:35,746 [INFO] Testing combination 104/150: {'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 15
Epoch    19: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 20
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 22
Epoch    26: reducing learning rate of group 0 to 1.0000e-06.
Epoch    30: reducing learning rate of group 0 to 1.0000e-07.
2024-10-05 22:02:47,339 [INFO] curr best accuracy: 88.58, params: {'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}
2024-10-05 22:02:47,339 [INFO] Testing combination 105/150: {'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 17
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 19
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 20
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 21
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 24
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 26
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 28
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 31
Epoch    35: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 36
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 37
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 38
Epoch    42: reducing learning rate of group 0 to 1.0000e-06.
Epoch    46: reducing learning rate of group 0 to 1.0000e-07.
2024-10-05 22:05:32,394 [INFO] curr best accuracy: 87.86, params: {'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}
2024-10-05 22:05:32,394 [INFO] Testing combination 106/150: {'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 9
Epoch    13: reducing learning rate of group 0 to 1.0000e-04.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 14
Epoch    18: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 19
Epoch    23: reducing learning rate of group 0 to 1.0000e-06.
Epoch    27: reducing learning rate of group 0 to 1.0000e-07.
2024-10-05 22:06:42,313 [INFO] curr best accuracy: 88.92, params: {'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}
2024-10-05 22:06:42,314 [INFO] Testing combination 107/150: {'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 16
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 17
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 19
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 20
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 21
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 24
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 25
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 28
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 29
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 30
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 31
Epoch    35: reducing learning rate of group 0 to 1.0000e-04.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 36
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 38
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 39
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 42
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 45
Epoch    49: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 50
Epoch    54: reducing learning rate of group 0 to 1.0000e-06.
Epoch    58: reducing learning rate of group 0 to 1.0000e-07.
2024-10-05 22:11:44,859 [INFO] curr best accuracy: 87.08, params: {'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}
2024-10-05 22:11:44,859 [INFO] Testing combination 108/150: {'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 6
Epoch    10: reducing learning rate of group 0 to 1.0000e-04.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 16
Epoch    20: reducing learning rate of group 0 to 1.0000e-05.
2024-10-05 22:13:44,283 [INFO] curr best accuracy: 89.14, params: {'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}
2024-10-05 22:13:44,284 [INFO] Testing combination 109/150: {'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 16
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 17
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 18
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 19
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 20
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 21
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 22
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 23
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 24
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 25
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 26
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 27
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 28
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 29
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 31
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 32
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 33
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 34
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 36
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 37
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 38
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 39
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 41
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 42
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 43
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 44
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 45
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 47
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 49
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 50
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 52
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 54
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 56
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 58
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 60
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 61
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 63
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 64
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 66
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 70
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 73
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 75
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 76
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 80
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 81
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 82
Epoch    86: reducing learning rate of group 0 to 1.0000e-05.
2024-10-05 22:18:35,838 [INFO] curr best accuracy: 86.6, params: {'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}
2024-10-05 22:18:35,839 [INFO] Testing combination 110/150: {'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 7
Epoch    11: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 15
Epoch    19: reducing learning rate of group 0 to 1.0000e-06.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 20
Epoch    24: reducing learning rate of group 0 to 1.0000e-07.
Epoch    28: reducing learning rate of group 0 to 1.0000e-08.
2024-10-05 22:20:31,144 [INFO] curr best accuracy: 89.12, params: {'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}
2024-10-05 22:20:31,145 [INFO] Testing combination 111/150: {'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 15
Epoch    19: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 20
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 21
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 22
Epoch    26: reducing learning rate of group 0 to 1.0000e-06.
2024-10-05 22:22:15,226 [INFO] curr best accuracy: 89.0, params: {'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}
2024-10-05 22:22:15,227 [INFO] Testing combination 112/150: {'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 16
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 17
Epoch    21: reducing learning rate of group 0 to 1.0000e-04.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 22
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 23
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 24
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 27
Epoch    31: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 32
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 35
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 37
Epoch    41: reducing learning rate of group 0 to 1.0000e-06.
Epoch    45: reducing learning rate of group 0 to 1.0000e-07.
2024-10-05 22:24:56,699 [INFO] curr best accuracy: 88.66, params: {'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}
2024-10-05 22:24:56,700 [INFO] Testing combination 113/150: {'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 17
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 19
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 20
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 22
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 23
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 26
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 27
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 31
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 34
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 35
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 36
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 37
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 41
Epoch    45: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 46
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 48
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 49
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 52
Epoch    56: reducing learning rate of group 0 to 1.0000e-06.
2024-10-05 22:26:34,252 [INFO] curr best accuracy: 89.34, params: {'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}
2024-10-05 22:26:34,253 [INFO] Testing combination 114/150: {'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 12
Epoch    16: reducing learning rate of group 0 to 1.0000e-04.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 17
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 18
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 19
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 21
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 22
Epoch    26: reducing learning rate of group 0 to 1.0000e-05.
2024-10-05 22:27:34,561 [INFO] curr best accuracy: 88.84, params: {'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}
2024-10-05 22:27:34,561 [INFO] Testing combination 115/150: {'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 15
Epoch    19: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 20
Epoch    24: reducing learning rate of group 0 to 1.0000e-06.
2024-10-05 22:30:15,246 [INFO] curr best accuracy: 89.6, params: {'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}
2024-10-05 22:30:15,247 [INFO] Testing combination 116/150: {'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 19
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 20
Epoch    24: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 25
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 27
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 30
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 34
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 38
Epoch    42: reducing learning rate of group 0 to 1.0000e-06.
2024-10-05 22:32:42,831 [INFO] curr best accuracy: 88.12, params: {'lr': 0.0001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}
2024-10-05 22:32:42,832 [INFO] Testing combination 117/150: {'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 18
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 22
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 23
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 25
Epoch    29: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 31
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 33
Epoch    37: reducing learning rate of group 0 to 1.0000e-06.
Epoch    41: reducing learning rate of group 0 to 1.0000e-07.
2024-10-05 22:36:43,807 [INFO] curr best accuracy: 88.9, params: {'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}
2024-10-05 22:36:43,808 [INFO] Testing combination 118/150: {'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 17
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 19
Epoch    23: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 24
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 25
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 27
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 29
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 33
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 34
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 37
Epoch    41: reducing learning rate of group 0 to 1.0000e-06.
Epoch    45: reducing learning rate of group 0 to 1.0000e-07.
2024-10-05 22:38:39,045 [INFO] curr best accuracy: 88.08, params: {'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}
2024-10-05 22:38:39,046 [INFO] Testing combination 119/150: {'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 16
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 17
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 18
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 19
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 20
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 21
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 23
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 25
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 26
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 27
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 29
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 31
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 33
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 34
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 36
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 37
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 39
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 40
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 41
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 42
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 45
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 47
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 49
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 50
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 53
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 55
Epoch    59: reducing learning rate of group 0 to 1.0000e-04.
Epoch    63: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 64
Epoch    68: reducing learning rate of group 0 to 1.0000e-06.
Epoch    72: reducing learning rate of group 0 to 1.0000e-07.
2024-10-05 22:40:32,091 [INFO] curr best accuracy: 86.3, params: {'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}
2024-10-05 22:40:32,091 [INFO] Testing combination 120/150: {'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 16
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 17
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 18
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 19
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 20
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 21
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 23
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 24
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 25
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 26
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 27
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 28
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 29
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 30
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 31
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 32
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 33
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 34
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 35
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 36
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 37
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 38
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 39
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 40
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 41
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 42
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 45
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 47
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 50
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 51
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 52
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 53
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 54
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 55
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 56
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 57
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 58
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 60
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 61
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 63
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 64
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 65
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 66
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 69
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 71
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 72
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 74
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 75
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 78
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 79
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 80
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 81
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 82
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 83
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 84
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 88
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 89
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 90
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 91
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 92
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 93
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 95
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 97
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 98
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 99
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 102
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 105
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 107
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 109
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 110
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 111
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 112
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 116
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 119
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 120
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 121
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 123
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 124
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 125
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 127
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 129
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 130
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 132
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 136
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 139
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 140
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 143
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 145
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 146
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 148
Epoch   152: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 153
Epoch   157: reducing learning rate of group 0 to 1.0000e-06.
Epoch   161: reducing learning rate of group 0 to 1.0000e-07.
2024-10-05 22:44:35,503 [INFO] curr best accuracy: 80.54, params: {'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}
2024-10-05 22:44:35,503 [INFO] Testing combination 121/150: {'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 16
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 17
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 18
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 19
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 20
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 22
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 23
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 24
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 26
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 27
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 28
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 29
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 31
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 32
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 34
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 36
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 40
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 44
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 45
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 46
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 47
Epoch    51: reducing learning rate of group 0 to 1.0000e-04.
2024-10-05 22:46:17,998 [INFO] curr best accuracy: 85.0, params: {'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}
2024-10-05 22:46:17,999 [INFO] Testing combination 122/150: {'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 16
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 17
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 18
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 19
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 20
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 21
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 22
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 23
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 24
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 26
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 28
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 30
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 31
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 32
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 33
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 34
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 35
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 36
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 37
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 38
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 40
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 41
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 42
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 43
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 45
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 46
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 47
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 48
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 49
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 50
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 52
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 53
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 56
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 57
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 58
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 60
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 61
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 63
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 64
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 65
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 66
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 67
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 70
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 71
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 72
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 75
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 76
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 77
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 78
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 82
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 83
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 85
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 86
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 87
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 88
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 89
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 92
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 93
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 94
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 97
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 98
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 99
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 102
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 103
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 104
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 107
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 109
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 111
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 115
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 116
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 118
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 119
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 120
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 121
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 125
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 127
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 128
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 130
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 131
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 133
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 134
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 136
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 139
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 140
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 142
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 145
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 146
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 149
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 151
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 155
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 156
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 160
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 164
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 167
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 168
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 170
Epoch   174: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 176
Epoch   180: reducing learning rate of group 0 to 1.0000e-06.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 181
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 182
Epoch   186: reducing learning rate of group 0 to 1.0000e-07.
Epoch   190: reducing learning rate of group 0 to 1.0000e-08.
2024-10-05 22:55:37,785 [INFO] curr best accuracy: 83.58, params: {'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}
2024-10-05 22:55:37,785 [INFO] Testing combination 123/150: {'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 4
Epoch     8: reducing learning rate of group 0 to 1.0000e-04.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 10
Epoch    14: reducing learning rate of group 0 to 1.0000e-05.
Epoch    18: reducing learning rate of group 0 to 1.0000e-06.
2024-10-05 22:56:47,645 [INFO] curr best accuracy: 89.14, params: {'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}
2024-10-05 22:56:47,646 [INFO] Testing combination 124/150: {'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 9
Epoch    13: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 17
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 20
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 21
Epoch    25: reducing learning rate of group 0 to 1.0000e-06.
2024-10-05 22:57:32,532 [INFO] curr best accuracy: 88.62, params: {'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}
2024-10-05 22:57:32,532 [INFO] Testing combination 125/150: {'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 16
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 17
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 18
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 20
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 21
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 22
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 23
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 24
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 25
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 26
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 27
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 28
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 30
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 32
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 34
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 35
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 36
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 37
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 39
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 41
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 42
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 46
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 47
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 48
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 49
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 53
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 54
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 57
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 58
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 61
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 62
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 64
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 66
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 68
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 71
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 73
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 75
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 77
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 79
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 80
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 84
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 88
Epoch    92: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 94
Epoch    98: reducing learning rate of group 0 to 1.0000e-06.
Epoch   102: reducing learning rate of group 0 to 1.0000e-07.
2024-10-05 23:06:47,260 [INFO] curr best accuracy: 85.34, params: {'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': None, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}
2024-10-05 23:06:47,260 [INFO] Testing combination 126/150: {'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 12
Epoch    16: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 17
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 18
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 19
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 21
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 22
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 26
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 27
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 31
Epoch    35: reducing learning rate of group 0 to 1.0000e-06.
2024-10-05 23:08:07,056 [INFO] curr best accuracy: 88.86, params: {'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}
2024-10-05 23:08:07,057 [INFO] Testing combination 127/150: {'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 12
Epoch    16: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 17
Epoch    21: reducing learning rate of group 0 to 1.0000e-06.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 24
Epoch    28: reducing learning rate of group 0 to 1.0000e-07.
Epoch    32: reducing learning rate of group 0 to 1.0000e-08.
2024-10-05 23:11:18,277 [INFO] curr best accuracy: 88.84, params: {'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}
2024-10-05 23:11:18,277 [INFO] Testing combination 128/150: {'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 7
Epoch    11: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 12
Epoch    16: reducing learning rate of group 0 to 1.0000e-06.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 17
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 18
Epoch    22: reducing learning rate of group 0 to 1.0000e-07.
Epoch    26: reducing learning rate of group 0 to 1.0000e-08.
2024-10-05 23:14:12,456 [INFO] curr best accuracy: 89.38, params: {'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}
2024-10-05 23:14:12,457 [INFO] Testing combination 129/150: {'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 18
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 22
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 25
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 27
Epoch    31: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 32
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 36
Epoch    40: reducing learning rate of group 0 to 1.0000e-06.
2024-10-05 23:15:24,027 [INFO] curr best accuracy: 89.28, params: {'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 256, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}
2024-10-05 23:15:24,027 [INFO] Testing combination 130/150: {'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 19
Epoch    23: reducing learning rate of group 0 to 1.0000e-04.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 24
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 25
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 27
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 28
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 29
Epoch    33: reducing learning rate of group 0 to 1.0000e-05.
Epoch    37: reducing learning rate of group 0 to 1.0000e-06.
2024-10-05 23:19:35,170 [INFO] curr best accuracy: 89.28, params: {'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}
2024-10-05 23:19:35,171 [INFO] Testing combination 131/150: {'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 16
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 18
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 19
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 20
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 21
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 22
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 23
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 24
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 25
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 26
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 27
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 28
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 29
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 30
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 31
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 32
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 33
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 34
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 35
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 36
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 37
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 38
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 39
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 40
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 41
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 42
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 44
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 45
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 47
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 48
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 49
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 51
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 52
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 53
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 54
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 56
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 57
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 58
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 60
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 62
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 64
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 66
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 67
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 68
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 70
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 74
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 76
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 77
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 78
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 80
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 81
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 83
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 84
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 85
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 88
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 91
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 93
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 95
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 96
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 98
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 100
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 104
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 106
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 110
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 113
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 114
Epoch   118: reducing learning rate of group 0 to 1.0000e-05.
2024-10-05 23:25:23,994 [INFO] curr best accuracy: 82.8, params: {'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}
2024-10-05 23:25:23,995 [INFO] Testing combination 132/150: {'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 16
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 19
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 20
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 22
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 26
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 27
Epoch    31: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 32
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 35
Epoch    39: reducing learning rate of group 0 to 1.0000e-06.
Epoch    43: reducing learning rate of group 0 to 1.0000e-07.
2024-10-05 23:27:00,129 [INFO] curr best accuracy: 88.12, params: {'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 10}
2024-10-05 23:27:00,130 [INFO] Testing combination 133/150: {'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 11
Epoch    15: reducing learning rate of group 0 to 1.0000e-04.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 16
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 17
Epoch    21: reducing learning rate of group 0 to 1.0000e-05.
Epoch    25: reducing learning rate of group 0 to 1.0000e-06.
2024-10-05 23:28:44,102 [INFO] curr best accuracy: 88.58, params: {'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}
2024-10-05 23:28:44,102 [INFO] Testing combination 134/150: {'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 5
Epoch     9: reducing learning rate of group 0 to 1.0000e-04.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 16
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 19
Epoch    23: reducing learning rate of group 0 to 1.0000e-05.
2024-10-05 23:30:17,455 [INFO] curr best accuracy: 89.6, params: {'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.1, 'batch_size': 64, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}
2024-10-05 23:30:17,455 [INFO] Testing combination 135/150: {'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 17
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 19
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 22
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 25
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 27
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 28
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 30
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 31
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 35
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 36
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 40
Epoch    44: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 45
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 46
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 50
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 51
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 54
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 55
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 57
Epoch    61: reducing learning rate of group 0 to 1.0000e-06.
2024-10-05 23:32:48,387 [INFO] curr best accuracy: 89.14, params: {'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}
2024-10-05 23:32:48,387 [INFO] Testing combination 136/150: {'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 6
Epoch    10: reducing learning rate of group 0 to 1.0000e-04.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 11
Epoch    15: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 16
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 17
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 21
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 23
Epoch    27: reducing learning rate of group 0 to 1.0000e-06.
Epoch    31: reducing learning rate of group 0 to 1.0000e-07.
2024-10-05 23:34:01,822 [INFO] curr best accuracy: 88.96, params: {'lr': 0.001, 'hidden_sizes': [256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}
2024-10-05 23:34:01,823 [INFO] Testing combination 137/150: {'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 6
Epoch    10: reducing learning rate of group 0 to 1.0000e-04.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 14
Epoch    18: reducing learning rate of group 0 to 1.0000e-05.
Epoch    22: reducing learning rate of group 0 to 1.0000e-06.
2024-10-05 23:36:31,956 [INFO] curr best accuracy: 89.46, params: {'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': None, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}
2024-10-05 23:36:31,957 [INFO] Testing combination 138/150: {'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 16
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 17
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 18
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 19
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 20
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 21
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 22
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 23
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 24
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 25
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 26
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 28
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 29
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 30
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 31
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 32
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 33
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 34
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 35
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 36
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 37
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 38
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 40
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 41
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 42
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 43
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 44
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 45
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 46
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 47
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 48
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 49
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 51
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 53
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 54
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 55
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 56
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 57
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 59
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 60
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 61
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 63
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 65
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 66
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 67
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 69
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 71
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 73
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 74
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 75
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 76
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 77
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 78
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 79
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 80
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 81
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 83
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 84
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 86
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 87
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 88
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 89
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 92
Epoch    96: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 97
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 98
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 99
Epoch   103: reducing learning rate of group 0 to 1.0000e-06.
2024-10-05 23:45:13,799 [INFO] curr best accuracy: 83.04, params: {'lr': 0.0001, 'hidden_sizes': [128, 128], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}
2024-10-05 23:45:13,800 [INFO] Testing combination 139/150: {'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 19
Epoch    23: reducing learning rate of group 0 to 1.0000e-04.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 24
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 25
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 27
Epoch    31: reducing learning rate of group 0 to 1.0000e-05.
Epoch    35: reducing learning rate of group 0 to 1.0000e-06.
2024-10-05 23:48:35,022 [INFO] curr best accuracy: 88.52, params: {'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': '', 'activation': 'relu', 'early_stopping': 10}
2024-10-05 23:48:35,023 [INFO] Testing combination 140/150: {'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 16
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 18
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 19
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 21
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 22
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 25
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 26
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 27
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 31
Epoch    35: reducing learning rate of group 0 to 1.0000e-04.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 36
Epoch    40: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 41
Epoch    45: reducing learning rate of group 0 to 1.0000e-06.
Epoch    49: reducing learning rate of group 0 to 1.0000e-07.
2024-10-05 23:51:04,744 [INFO] curr best accuracy: 87.08, params: {'lr': 0.001, 'hidden_sizes': [128, 128], 'p_dropout': None, 'batch_size': 64, 'normalization': '', 'activation': 'lrelu', 'early_stopping': 10}
2024-10-05 23:51:04,745 [INFO] Testing combination 141/150: {'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 15
Epoch    19: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 20
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}.pt at epoch 21
Epoch    25: reducing learning rate of group 0 to 1.0000e-06.
2024-10-05 23:53:48,489 [INFO] curr best accuracy: 88.64, params: {'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 5}
2024-10-05 23:53:48,489 [INFO] Testing combination 142/150: {'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 18
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 20
Epoch    24: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 25
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 26
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 27
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 30
Epoch    34: reducing learning rate of group 0 to 1.0000e-06.
Epoch    38: reducing learning rate of group 0 to 1.0000e-07.
2024-10-05 23:58:06,471 [INFO] curr best accuracy: 89.62, params: {'lr': 0.0001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.3, 'batch_size': 32, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}
2024-10-05 23:58:06,472 [INFO] Testing combination 143/150: {'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 17
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 19
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 22
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 23
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 25
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 27
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 31
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 33
Epoch    37: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 38
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 39
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 43
Epoch    47: reducing learning rate of group 0 to 1.0000e-06.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 49
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 50
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 52
Epoch    56: reducing learning rate of group 0 to 1.0000e-07.
Epoch    60: reducing learning rate of group 0 to 1.0000e-08.
2024-10-05 23:59:57,347 [INFO] curr best accuracy: 88.28, params: {'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}
2024-10-05 23:59:57,347 [INFO] Testing combination 144/150: {'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 17
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 19
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 22
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 25
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 27
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 28
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 30
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 31
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 35
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 36
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 40
Epoch    44: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 45
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 46
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 50
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 51
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 54
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 55
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 57
Epoch    61: reducing learning rate of group 0 to 1.0000e-06.
Epoch    65: reducing learning rate of group 0 to 1.0000e-07.
2024-10-06 00:02:40,493 [INFO] curr best accuracy: 89.14, params: {'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 128, 'normalization': 'layer', 'activation': 'lrelu', 'early_stopping': 10}
2024-10-06 00:02:40,494 [INFO] Testing combination 145/150: {'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 8
Epoch    12: reducing learning rate of group 0 to 1.0000e-04.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 15
Epoch    19: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 23
Epoch    27: reducing learning rate of group 0 to 1.0000e-06.
Epoch    31: reducing learning rate of group 0 to 1.0000e-07.
2024-10-06 00:06:12,662 [INFO] curr best accuracy: 89.08, params: {'lr': 0.001, 'hidden_sizes': [512, 512, 512], 'p_dropout': 0.1, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}
2024-10-06 00:06:12,663 [INFO] Testing combination 146/150: {'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 10
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 16
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 17
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 18
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 19
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 20
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 21
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 22
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 23
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 24
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 25
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 26
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 27
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 29
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 30
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 31
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 33
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 34
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 35
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 36
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 37
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 39
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 40
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 42
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 43
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 44
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 46
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 47
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 48
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 49
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 50
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 52
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 53
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 54
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 56
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 57
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 59
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 60
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 61
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 63
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 64
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 65
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 66
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 67
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 68
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 71
Epoch    75: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 76
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 77
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 78
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 79
Epoch    83: reducing learning rate of group 0 to 1.0000e-06.
2024-10-06 00:08:55,373 [INFO] curr best accuracy: 78.88, params: {'lr': 0.0001, 'hidden_sizes': [256, 128], 'p_dropout': None, 'batch_size': 128, 'normalization': '', 'activation': 'relu', 'early_stopping': 5}
2024-10-06 00:08:55,374 [INFO] Testing combination 147/150: {'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 7
Epoch    11: reducing learning rate of group 0 to 1.0000e-04.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 18
Epoch    22: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}.pt at epoch 23
Epoch    27: reducing learning rate of group 0 to 1.0000e-06.
Epoch    31: reducing learning rate of group 0 to 1.0000e-07.
2024-10-06 00:09:49,446 [INFO] curr best accuracy: 88.64, params: {'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 10}
2024-10-06 00:09:49,447 [INFO] Testing combination 148/150: {'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 3
Epoch     7: reducing learning rate of group 0 to 1.0000e-04.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 11
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 12
Epoch    16: reducing learning rate of group 0 to 1.0000e-05.
Epoch    20: reducing learning rate of group 0 to 1.0000e-06.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}.pt at epoch 21
Epoch    25: reducing learning rate of group 0 to 1.0000e-07.
Epoch    29: reducing learning rate of group 0 to 1.0000e-08.
2024-10-06 00:10:58,117 [INFO] curr best accuracy: 88.82, params: {'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': 0.1, 'batch_size': 128, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 10}
2024-10-06 00:10:58,117 [INFO] Testing combination 149/150: {'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 7
Epoch    11: reducing learning rate of group 0 to 1.0000e-04.
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 15
*** Saved checkpoint checkpoints/mlp{'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 17
Epoch    21: reducing learning rate of group 0 to 1.0000e-05.
2024-10-06 00:13:02,184 [INFO] curr best accuracy: 88.76, params: {'lr': 0.001, 'hidden_sizes': [128, 64], 'p_dropout': None, 'batch_size': 32, 'normalization': 'batch', 'activation': 'relu', 'early_stopping': 5}
2024-10-06 00:13:02,184 [INFO] Testing combination 150/150: {'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 1
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 2
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 3
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 4
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 5
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 6
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 7
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 8
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 9
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 12
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 13
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 14
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 16
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 17
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 19
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 21
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 22
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 25
Epoch    29: reducing learning rate of group 0 to 1.0000e-05.
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 30
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 31
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 32
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 33
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 37
*** Saved checkpoint checkpoints/mlp{'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}.pt at epoch 38
Epoch    42: reducing learning rate of group 0 to 1.0000e-06.
2024-10-06 00:15:46,934 [INFO] curr best accuracy: 88.7, params: {'lr': 0.0001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 64, 'normalization': 'layer', 'activation': 'relu', 'early_stopping': 5}
2024-10-06 00:15:46,934 [INFO] Best Validation Accuracy: 89.8
2024-10-06 00:15:46,934 [INFO] Best Hyperparameters: {'lr': 0.001, 'hidden_sizes': [512, 256, 128], 'p_dropout': 0.3, 'batch_size': 256, 'normalization': 'batch', 'activation': 'lrelu', 'early_stopping': 5}
*** SLURM BATCH JOB 'galk-job' DONE ***
