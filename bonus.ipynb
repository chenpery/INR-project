{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a576b55d-9b5e-4dc9-8807-f15c21a50772",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "def dynamic_lambda(t, T, schedule='linear'):\n",
    "    \"\"\"\n",
    "    Compute dynamic lambda(t) based on the iteration number and schedule type.\n",
    "    \n",
    "    Args:\n",
    "        t (int): Current iteration (1-based index).\n",
    "        T (int): Total number of attack iterations.\n",
    "        schedule (str): Type of schedule ('linear', 'log', 'exp').\n",
    "        \n",
    "    Returns:\n",
    "        float: Lambda value for the current iteration.\n",
    "    \"\"\"\n",
    "    if schedule == 'linear':\n",
    "        return (t - 1) / (2 * T)\n",
    "    elif schedule == 'log':\n",
    "        return 0.5 * np.log2(1 + (t - 1) / T)\n",
    "    elif schedule == 'exp':\n",
    "        return 0.5 * (2 * (t - 1) / T - 1)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported schedule type. Choose from 'linear', 'log', 'exp'.\")\n",
    "\n",
    "def segpgd_attack(model, loader: DataLoader, criterion, linf_bound, num_pgd_steps=10, device=\"cuda\", schedule='linear'):\n",
    "    \"\"\"\n",
    "    Perform SegPGD attack on the segmentation model and evaluate its robustness.\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): Trained segmentation model.\n",
    "        loader (DataLoader): DataLoader for input data.\n",
    "        criterion (nn.Module): Loss function (e.g., CrossEntropyLoss).\n",
    "        linf_bound (float): Maximum perturbation (epsilon).\n",
    "        num_pgd_steps (int): Number of PGD attack steps.\n",
    "        device (str): Device to perform computations on ('cuda' or 'cpu').\n",
    "        schedule (str): Schedule type for lambda(t).\n",
    "        \n",
    "    Returns:\n",
    "        float: mIoU (mean Intersection over Union) after the attack.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_miou = 0.0\n",
    "    total_samples = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for vectors, labels in tqdm(loader, desc=\"SegPGD Attack\", total=len(loader)):\n",
    "            vectors, labels = vectors.to(device), labels.to(device)\n",
    "            batch_size, _, H, W = vectors.shape\n",
    "            # Initialize perturbations randomly within the l_inf ball\n",
    "            perts = torch.empty_like(vectors).uniform_(-linf_bound, linf_bound).to(device)\n",
    "            perts.requires_grad = True\n",
    "            \n",
    "            for t in range(1, num_pgd_steps + 1):\n",
    "                # Compute model predictions\n",
    "                outputs = model(vectors + perts)  # Shape: (batch_size, num_classes, H, W)\n",
    "                \n",
    "                # Get predicted classes\n",
    "                preds = torch.argmax(outputs, dim=1)  # Shape: (batch_size, H, W)\n",
    "                \n",
    "                # Determine correctly and incorrectly classified pixels\n",
    "                correct = (preds == labels)  # Shape: (batch_size, H, W)\n",
    "                incorrect = ~correct\n",
    "                \n",
    "                # Compute dynamic lambda(t)\n",
    "                lambda_t = dynamic_lambda(t, num_pgd_steps, schedule=schedule)\n",
    "                \n",
    "                # Compute loss\n",
    "                # Flatten tensors to shape (batch_size * H * W, ...)\n",
    "                correct = correct.view(-1)\n",
    "                incorrect = incorrect.view(-1)\n",
    "                outputs = outputs.permute(0, 2, 3, 1).reshape(-1, outputs.shape[1])  # Shape: (batch_size*H*W, num_classes)\n",
    "                labels_flat = labels.view(-1)  # Shape: (batch_size*H*W)\n",
    "                \n",
    "                # Cross-entropy loss for correct pixels\n",
    "                if correct.sum() > 0:\n",
    "                    loss_correct = criterion(outputs[correct], labels_flat[correct])\n",
    "                else:\n",
    "                    loss_correct = torch.tensor(0.0).to(device)\n",
    "                \n",
    "                # Cross-entropy loss for incorrect pixels\n",
    "                if incorrect.sum() > 0:\n",
    "                    loss_incorrect = criterion(outputs[incorrect], labels_flat[incorrect])\n",
    "                else:\n",
    "                    loss_incorrect = torch.tensor(0.0).to(device)\n",
    "                \n",
    "                # Weighted loss\n",
    "                loss = (1 - lambda_t) * loss_correct + lambda_t * loss_incorrect\n",
    "                \n",
    "                # Backward pass\n",
    "                model.zero_grad()\n",
    "                loss.backward()\n",
    "                \n",
    "                # Update perturbations\n",
    "                perts_grad = perts.grad.data\n",
    "                perts = perts + linf_bound / num_pgd_steps * perts_grad.sign()\n",
    "                \n",
    "                # Project perturbations back to l_inf ball\n",
    "                perts = torch.clamp(vectors + perts, min=vectors - linf_bound, max=vectors + linf_bound) - vectors\n",
    "                perts = perts.detach().requires_grad_()\n",
    "            \n",
    "            # After attack iterations, compute mIoU\n",
    "            with torch.no_grad():\n",
    "                adversarial_vectors = vectors + perts\n",
    "                adversarial_outputs = model(adversarial_vectors)\n",
    "                adversarial_preds = torch.argmax(adversarial_outputs, dim=1)  # Shape: (batch_size, H, W)\n",
    "                \n",
    "                # Compute mIoU for the batch\n",
    "                miou = compute_miou(adversarial_preds, labels, num_classes=outputs.shape[1])\n",
    "                total_miou += miou * batch_size\n",
    "                total_samples += batch_size\n",
    "    \n",
    "    average_miou = total_miou / total_samples\n",
    "    print(f'Average mIoU after SegPGD attack with l_inf_bound={linf_bound}: {average_miou:.2f}%')\n",
    "    return average_miou\n",
    "\n",
    "def compute_miou(preds, labels, num_classes):\n",
    "    \"\"\"\n",
    "    Compute mean Intersection over Union (mIoU) for a batch of predictions and labels.\n",
    "    \n",
    "    Args:\n",
    "        preds (torch.Tensor): Predicted labels. Shape: (batch_size, H, W)\n",
    "        labels (torch.Tensor): Ground truth labels. Shape: (batch_size, H, W)\n",
    "        num_classes (int): Number of classes.\n",
    "        \n",
    "    Returns:\n",
    "        float: mIoU score.\n",
    "    \"\"\"\n",
    "    miou = 0.0\n",
    "    for cls in range(num_classes):\n",
    "        pred_inds = (preds == cls)\n",
    "        target_inds = (labels == cls)\n",
    "        intersection = (pred_inds & target_inds).sum().item()\n",
    "        union = (pred_inds | target_inds).sum().item()\n",
    "        if union == 0:\n",
    "            continue  # Skip if there is no ground truth for this class\n",
    "        miou += intersection / union\n",
    "    miou /= num_classes\n",
    "    return miou * 100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
